{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1c6276",
   "metadata": {},
   "source": [
    "# Homework 1: kNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be9c01",
   "metadata": {},
   "source": [
    "#### Import packages and load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6b405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mnist_dataloader\n",
    "import mnist_viewer\n",
    "\n",
    "\n",
    "mnist_dataset = mnist_dataloader.read_data_sets(\"./MNIST_dataset/\")\n",
    "# generate 3 datasets: A (train), B (test), C (A & B mixed)\n",
    "dataset_A, dataset_B, dataset_C = mnist_dataset.train, mnist_dataset.test, mnist_dataset.multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf91593c",
   "metadata": {},
   "source": [
    "#### Visualization (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345218ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = dataset_A.num_examples\n",
    "test_size = dataset_B.num_examples\n",
    "print('Dataset size:', '(train, test) =', (train_size, test_size))\n",
    "\n",
    "# you can modify parameter {idx: 0 ~ 6000} to choose any image in dataset to visualize\n",
    "mnist_viewer.view(dataset_C, idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839117e4",
   "metadata": {},
   "source": [
    "#### Generate subset A, B and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd77409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use index to get specific item (e.g. image_A[0])\n",
    "images_A, images_B, images_C = dataset_A.images, dataset_B.images, dataset_C.images\n",
    "labels_A, labels_B, labels_C = dataset_A.labels, dataset_B.labels, dataset_C.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f1c488",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a825f6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_dataset/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_dataset/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_dataset/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_dataset/t10k-labels-idx1-ubyte.gz\n",
      "采用基于欧几里德距离的最近邻分类器准确率为 0.9746666666666667 用时为 37.97606015205383 s\n"
     ]
    }
   ],
   "source": [
    "# TODO: Euclidean nearest classifier\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import mnist_dataloader\n",
    "import mnist_viewer\n",
    "\n",
    "mnist_dataset = mnist_dataloader.read_data_sets(\"./MNIST_dataset/\")\n",
    "\n",
    "# 获取测试数据集\n",
    "test_images = mnist_dataset.test.images\n",
    "test_labels = mnist_dataset.test.labels\n",
    "\n",
    "# 从测试数据集中随机选择6000个样本作为数据集C\n",
    "np.random.seed(42)  # 设置随机种子以确保结果可重现\n",
    "indices_C = np.random.choice(len(test_images), size=6000, replace=True)\n",
    "\n",
    "# 创建数据集C\n",
    "dataset_C_images = test_images[indices_C]\n",
    "dataset_C_labels = test_labels[indices_C]\n",
    "\n",
    "\n",
    "# 将数据集C均分为两部分：数据集A和数据集B\n",
    "split_point = len(dataset_C_images) // 2\n",
    "dataset_A_images = dataset_C_images[:split_point]\n",
    "dataset_A_labels = dataset_C_labels[:split_point]\n",
    "dataset_B_images = dataset_C_images[split_point:]\n",
    "dataset_B_labels = dataset_C_labels[split_point:]\n",
    "\n",
    "#将训练集与测试集中原本28*28的二维矩阵数据转变为1*784的一维矩阵，便于求欧氏距离的计算\n",
    "A = np.zeros((3000, 784))\n",
    "B = np.zeros((3000, 784))\n",
    "for i in range (3000):\n",
    "    A[i,:] = dataset_A_images[i].reshape(784)\n",
    "for j in range (3000):\n",
    "    B[j,:] = dataset_B_images[j].reshape(784)\n",
    "    \n",
    "#定义储存测试标签的数组y_labels\n",
    "y_labels = np.zeros((3000,1))\n",
    "\n",
    "#记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "#对每一个测试集数据，计算与每一个训练集数据的欧式距离，并挑选最近邻的元素，将其标签作为判定结果\n",
    "distances = np.zeros((1,3000))\n",
    "for j in range(3000):\n",
    "    # 计算B中第j个样本与A中所有样本的欧几里得距离\n",
    "    distances = np.sqrt(np.sum(np.square(A - B[j, :]), axis=1))\n",
    "    # 找到最小距离的索引\n",
    "    min_index = np.argmin(distances)\n",
    "    # 使用最小距离对应的训练样本标签作为预测结果\n",
    "    y_labels[j] = dataset_A_labels[min_index]   \n",
    "\n",
    "\n",
    "#记录结束时间\n",
    "end_time = time.time()\n",
    "\n",
    "#计算准确率和所需时间\n",
    "accuracy = np.mean(np.squeeze(y_labels) == dataset_B_labels)\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print('采用基于欧几里德距离的最近邻分类器准确率为',accuracy,'用时为',time_taken,'s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61aa89b4",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7df1bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_dataset/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_dataset/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_dataset/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_dataset/t10k-labels-idx1-ubyte.gz\n",
      "曼哈顿距离下的准确率： 0.973\n",
      "曼哈顿距离所用时间： 41.05406069755554\n",
      "切比雪夫距离下的准确率： 0.8543333333333333\n",
      "切比雪夫距离所用时间： 38.2518253326416\n",
      "闵可夫斯基距离下的准确率： 0.9803333333333333\n",
      "闵可夫斯基距离所用时间： 127.22295427322388\n"
     ]
    }
   ],
   "source": [
    "# TODO: different distance metrics\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import mnist_dataloader\n",
    "import mnist_viewer\n",
    "\n",
    "mnist_dataset = mnist_dataloader.read_data_sets(\"./MNIST_dataset/\")\n",
    "\n",
    "# 获取测试数据集\n",
    "test_images = mnist_dataset.test.images\n",
    "test_labels = mnist_dataset.test.labels\n",
    "\n",
    "# 从测试数据集中随机选择6000个样本作为数据集C\n",
    "np.random.seed(42)  # 设置随机种子以确保结果可重现\n",
    "indices_C = np.random.choice(len(test_images), size=6000, replace=True)\n",
    "\n",
    "# 创建数据集C\n",
    "dataset_C_images = test_images[indices_C]\n",
    "dataset_C_labels = test_labels[indices_C]\n",
    "\n",
    "\n",
    "# 将数据集C均分为两部分：数据集A和数据集B\n",
    "split_point = len(dataset_C_images) // 2\n",
    "dataset_A_images = dataset_C_images[:split_point]\n",
    "dataset_A_labels = dataset_C_labels[:split_point]\n",
    "dataset_B_images = dataset_C_images[split_point:]\n",
    "dataset_B_labels = dataset_C_labels[split_point:]\n",
    "\n",
    "#将训练集与测试集中原本28*28的二维矩阵数据转变为1*784的一维矩阵，便于距离的计算\n",
    "A = np.zeros((3000, 784))\n",
    "B = np.zeros((3000, 784))\n",
    "for i in range (3000):\n",
    "    A[i,:] = dataset_A_images[i].reshape(784)\n",
    "for j in range (3000):\n",
    "    B[j,:] = dataset_B_images[j].reshape(784)\n",
    "    \n",
    "#定义储存测试标签的数组y_labels\n",
    "y_labels_Ma = np.zeros((3000,1))\n",
    "\n",
    "#记录开始时间\n",
    "start_time_Ma = time.time()\n",
    "\n",
    "#对每一个测试集数据，计算与每一个训练集数据的曼哈顿距离，并挑选最近邻的元素，将其标签作为判定结果\n",
    "distances_Ma = np.zeros((1,3000))\n",
    "for j in range(3000):\n",
    "    # 计算B中第j个样本与A中所有样本的曼哈顿距离\n",
    "    distances_Ma = np.sum(np.abs(A-B[j,:]),axis=1)\n",
    "    # 找到最小距离的索引\n",
    "    min_index_Ma = np.argmin(distances_Ma)\n",
    "    # 使用最小距离对应的训练样本标签作为预测结果\n",
    "    y_labels_Ma[j] = dataset_A_labels[min_index_Ma]   \n",
    "\n",
    "#记录结束时间\n",
    "end_time_Ma = time.time()\n",
    "\n",
    "#计算准确率和所需时间\n",
    "accuracy_Ma = np.mean(np.squeeze(y_labels_Ma) == dataset_B_labels)\n",
    "time_taken_Ma = end_time_Ma - start_time_Ma\n",
    "\n",
    "######################切比雪夫距离########################\n",
    "\n",
    "#定义储存测试标签的数组y_labels\n",
    "y_labels_Ch = np.zeros((3000,1))\n",
    "\n",
    "#记录开始时间\n",
    "start_time_Ch = time.time()\n",
    "\n",
    "#对每一个测试集数据，计算与每一个训练集数据的闵可夫斯基距离，并挑选最近邻的元素，将其标签作为判定结果\n",
    "distances_Ch = np.zeros((1,3000))\n",
    "for j in range(3000):\n",
    "    # 计算B中第j个样本与A中所有样本的曼哈顿距离\n",
    "    distances_Ch = np.max(np.abs(A-B[j,:]),axis=1)\n",
    "    # 找到最小距离的索引\n",
    "    min_index_Ch = np.argmin(distances_Ch)\n",
    "    # 使用最小距离对应的训练样本标签作为预测结果\n",
    "    y_labels_Ch[j] = dataset_A_labels[min_index_Ch]   \n",
    "\n",
    "#记录结束时间\n",
    "end_time_Ch = time.time()\n",
    "\n",
    "#计算准确率和所需时间\n",
    "accuracy_Ch = np.mean(np.squeeze(y_labels_Ch) == dataset_B_labels)\n",
    "time_taken_Ch = end_time_Ch - start_time_Ch\n",
    "\n",
    "######################p=4闵可夫斯基距离###################\n",
    "\n",
    "#定义储存测试标签的数组y_labels\n",
    "y_labels_Mi = np.zeros((3000,1))\n",
    "\n",
    "#记录开始时间\n",
    "start_time_Mi = time.time()\n",
    "\n",
    "#对每一个测试集数据，计算与每一个训练集数据的闵可夫斯基距离，并挑选最近邻的元素，将其标签作为判定结果\n",
    "distances_Mi = np.zeros((1,3000))\n",
    "for j in range(3000):\n",
    "    # 计算B中第j个样本与A中所有样本的曼哈顿距离\n",
    "    distances_Mi = np.power(np.sum(np.abs(A-B[j,:])**4,axis=1),0.25)\n",
    "    # 找到最小距离的索引\n",
    "    min_index_Mi = np.argmin(distances_Mi)\n",
    "    # 使用最小距离对应的训练样本标签作为预测结果\n",
    "    y_labels_Mi[j] = dataset_A_labels[min_index_Mi]   \n",
    "\n",
    "#记录结束时间\n",
    "end_time_Mi = time.time()\n",
    "\n",
    "#计算准确率和所需时间\n",
    "accuracy_Mi = np.mean(np.squeeze(y_labels_Mi) == dataset_B_labels)\n",
    "time_taken_Mi = end_time_Mi - start_time_Mi\n",
    "\n",
    "print('曼哈顿距离下的准确率：',accuracy_Ma)\n",
    "print('曼哈顿距离所用时间：',time_taken_Ma)\n",
    "print('切比雪夫距离下的准确率：',accuracy_Ch)\n",
    "print('切比雪夫距离所用时间：',time_taken_Ch)\n",
    "print('闵可夫斯基距离下的准确率：',accuracy_Mi)\n",
    "print('闵可夫斯基距离所用时间：',time_taken_Mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d1fae",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff055b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_dataset/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_dataset/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_dataset/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_dataset/t10k-labels-idx1-ubyte.gz\n",
      "k= 3 准确率为 0.9746666666666667 所用时间 41.43443751335144\n",
      "k= 5 准确率为 0.96 所用时间 46.68027663230896\n",
      "k= 7 准确率为 0.942 所用时间 44.34632658958435\n",
      "k= 11 准确率为 0.9253333333333333 所用时间 41.82025480270386\n",
      "k= 21 准确率为 0.904 所用时间 40.24078416824341\n"
     ]
    }
   ],
   "source": [
    "# TODO: kNN classifier\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import mnist_dataloader\n",
    "import mnist_viewer\n",
    "from collections import Counter\n",
    "\n",
    "mnist_dataset = mnist_dataloader.read_data_sets(\"./MNIST_dataset/\")\n",
    "\n",
    "#使用NumPy找到向量中最小的k个数的索引\n",
    "def find_smallest_k_indices_np(vector, k):\n",
    "    \n",
    "    arr = np.array(vector)\n",
    "    # 使用argpartition提高性能，特别是当k远小于数组大小时\n",
    "    indices = np.argpartition(arr, k-1)[:(k-1)]\n",
    "    # 对结果进行排序，使索引按对应值从小到大排列\n",
    "    indices = indices[np.argsort(arr[indices])]\n",
    "    return indices\n",
    "\n",
    "\n",
    "# 获取测试数据集\n",
    "test_images = mnist_dataset.test.images\n",
    "test_labels = mnist_dataset.test.labels\n",
    "\n",
    "# 从测试数据集中随机选择6000个样本作为数据集C\n",
    "np.random.seed(42)  # 设置随机种子以确保结果可重现\n",
    "indices_C = np.random.choice(len(test_images), size=6000, replace=True)\n",
    "\n",
    "# 创建数据集C\n",
    "dataset_C_images = test_images[indices_C]\n",
    "dataset_C_labels = test_labels[indices_C]\n",
    "\n",
    "\n",
    "# 将数据集C均分为两部分：数据集A和数据集B\n",
    "split_point = len(dataset_C_images) // 2\n",
    "dataset_A_images = dataset_C_images[:split_point]\n",
    "dataset_A_labels = dataset_C_labels[:split_point]\n",
    "dataset_B_images = dataset_C_images[split_point:]\n",
    "dataset_B_labels = dataset_C_labels[split_point:]\n",
    "\n",
    "#将训练集与测试集中原本28*28的二维矩阵数据转变为1*784的一维矩阵，便于求欧氏距离的计算\n",
    "A = np.zeros((3000, 784))\n",
    "B = np.zeros((3000, 784))\n",
    "for i in range (3000):\n",
    "    A[i,:] = dataset_A_images[i].reshape(784)\n",
    "for j in range (3000):\n",
    "    B[j,:] = dataset_B_images[j].reshape(784)\n",
    "\n",
    "for k in [3,5,7,11,21]:\n",
    "    #定义储存测试标签的数组y_labels\n",
    "    y_labels = np.zeros((3000,1))\n",
    "\n",
    "    #记录开始时间\n",
    "    start_time = time.time()\n",
    "\n",
    "    #对每一个测试集数据，计算与每一个训练集数据的欧式距离，并挑选最近邻的元素，将其标签作为判定结果\n",
    "    distances = np.zeros((1,3000))\n",
    "    for j in range(3000):\n",
    "        # 计算B中第j个样本与A中所有样本的欧几里得距离\n",
    "        distances = np.sqrt(np.sum(np.square(A - B[j, :]), axis=1))\n",
    "        # 找到最小距离的索引\n",
    "        results = find_smallest_k_indices_np(distances,k)\n",
    "        #找出出现次数最多的标签\n",
    "        result = Counter([dataset_A_labels[i] for i in results]).most_common(1)[0][0]\n",
    "        # 使用最小距离对应的训练样本标签作为预测结果\n",
    "        y_labels[j] = result   \n",
    "\n",
    "\n",
    "    #记录结束时间\n",
    "    end_time = time.time()\n",
    "\n",
    "    #计算准确率和所需时间\n",
    "    accuracy = np.mean(np.squeeze(y_labels) == dataset_B_labels)\n",
    "    time_taken = end_time - start_time\n",
    "\n",
    "    print('k=',k,'准确率为',accuracy,'所用时间',time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bad6af",
   "metadata": {},
   "source": [
    "## Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c435c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_dataset/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_dataset/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_dataset/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_dataset/t10k-labels-idx1-ubyte.gz\n",
      "留一法交叉检验的准确率为 0.9896666666666667 用时为为 152.23458290100098\n"
     ]
    }
   ],
   "source": [
    "# TOimport os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import mnist_dataloader\n",
    "import mnist_viewer\n",
    "\n",
    "mnist_dataset = mnist_dataloader.read_data_sets(\"./MNIST_dataset/\")\n",
    "\n",
    "# 获取测试数据集\n",
    "test_images = mnist_dataset.test.images\n",
    "test_labels = mnist_dataset.test.labels\n",
    "\n",
    "# 从测试数据集中随机选择6000个样本作为数据集C\n",
    "np.random.seed(42)  # 设置随机种子以确保结果可重现\n",
    "indices_C = np.random.choice(len(test_images), size=6000, replace=True)\n",
    "\n",
    "# 创建数据集C\n",
    "dataset_C_images = test_images[indices_C]\n",
    "dataset_C_labels = test_labels[indices_C]\n",
    "\n",
    "#将训练集与测试集中原本28*28的二维矩阵数据转变为1*784的一维矩阵，便于求欧氏距离的计算\n",
    "C = np.zeros((6000, 784))\n",
    "for i in range (6000):\n",
    "    C[i,:] = dataset_C_images[i].reshape(784)\n",
    "    \n",
    "#定义储存测试标签的数组y_labels\n",
    "y_labels = np.zeros((6000,1))\n",
    "\n",
    "#记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(6000):\n",
    "    distances = np.linalg.norm(C[i] - C, axis=1)\n",
    "    # 将当前样本与自身的距离设为无穷大，避免选择自己作为最近邻\n",
    "    distances[i] = np.inf\n",
    "    # 找到最近邻的索引\n",
    "    min_index = np.argmin(distances)\n",
    "    y_labels[i] = dataset_C_labels[min_index]\n",
    "\n",
    "#记录结束时间\n",
    "end_time = time.time()\n",
    "\n",
    "#计算准确率和所需时间\n",
    "accuracy = np.mean(np.squeeze(y_labels) == dataset_C_labels)\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "print('留一法交叉检验的准确率为',accuracy,'用时为为',time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cb3443",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a5a9c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_dataset/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_dataset/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_dataset/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_dataset/t10k-labels-idx1-ubyte.gz\n",
      "2倍降采样后准确率为 0.9786666666666667 用时为 4.47430944442749\n",
      "4倍降采样后准确率为 0.8923333333333333 用时为 0.4746990203857422\n",
      "2倍分辨率插值后准确率为 0.9796666666666667 用时为 81.8117139339447\n"
     ]
    }
   ],
   "source": [
    "# TODO: downsampling and upsampling\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import mnist_dataloader\n",
    "import mnist_viewer\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "mnist_dataset = mnist_dataloader.read_data_sets(\"./MNIST_dataset/\")\n",
    "\n",
    "# 获取测试数据集\n",
    "test_images = mnist_dataset.test.images\n",
    "test_labels = mnist_dataset.test.labels\n",
    "\n",
    "# 从测试数据集中随机选择6000个样本作为数据集C\n",
    "np.random.seed(42)  # 设置随机种子以确保结果可重现\n",
    "indices_C = np.random.choice(len(test_images), size=6000, replace=True)\n",
    "\n",
    "# 创建数据集C\n",
    "dataset_C_images = test_images[indices_C]\n",
    "dataset_C_labels = test_labels[indices_C]\n",
    "\n",
    "# 将数据集C均分为两部分：数据集A和数据集B\n",
    "split_point = len(dataset_C_images) // 2\n",
    "dataset_A_images = dataset_C_images[:split_point]\n",
    "dataset_A_labels = dataset_C_labels[:split_point]\n",
    "dataset_B_images = dataset_C_images[split_point:]\n",
    "dataset_B_labels = dataset_C_labels[split_point:]\n",
    "\n",
    "# 首先将一维图像数据重塑为二维 (28x28)\n",
    "dataset_A_images_2d = dataset_A_images.reshape(-1, 28, 28)\n",
    "dataset_B_images_2d = dataset_B_images.reshape(-1, 28, 28)\n",
    "\n",
    "#创建新的数据集\n",
    "dataset_A_images_2x_down = []\n",
    "dataset_A_images_4x_down = []\n",
    "dataset_A_images_2x_up = []\n",
    "dataset_B_images_2x_down = []\n",
    "dataset_B_images_4x_down = []\n",
    "dataset_B_images_2x_up = []\n",
    "\n",
    "for i in range (len(dataset_A_images_2d)):\n",
    "    downsampled = zoom(dataset_A_images_2d[i], (0.5, 0.5), order=1)\n",
    "    dataset_A_images_2x_down.append(downsampled)\n",
    "    downsampled = zoom(dataset_A_images_2d[i], (0.25, 0.25), order=1)\n",
    "    dataset_A_images_4x_down.append(downsampled)\n",
    "    downsampled = zoom(dataset_A_images_2d[i], (2.0, 2.0), order=1)\n",
    "    dataset_A_images_2x_up.append(downsampled)\n",
    "    downsampled = zoom(dataset_B_images_2d[i], (0.5, 0.5), order=1)\n",
    "    dataset_B_images_2x_down.append(downsampled)\n",
    "    downsampled = zoom(dataset_B_images_2d[i], (0.25, 0.25), order=1)\n",
    "    dataset_B_images_4x_down.append(downsampled)\n",
    "    downsampled = zoom(dataset_B_images_2d[i], (2.0, 2.0), order=1)\n",
    "    dataset_B_images_2x_up.append(downsampled)\n",
    "    \n",
    "# 转换为numpy数组\n",
    "dataset_A_images_2x_down = np.array(dataset_A_images_2x_down).reshape(len(dataset_A_images_2x_down), -1)\n",
    "dataset_A_images_4x_down = np.array(dataset_A_images_4x_down).reshape(len(dataset_A_images_4x_down), -1)\n",
    "dataset_A_images_2x_up = np.array(dataset_A_images_2x_up).reshape(len(dataset_A_images_2x_up), -1)\n",
    "dataset_B_images_2x_down = np.array(dataset_B_images_2x_down).reshape(len(dataset_B_images_2x_down), -1)\n",
    "dataset_B_images_4x_down = np.array(dataset_B_images_4x_down).reshape(len(dataset_B_images_4x_down), -1)\n",
    "dataset_B_images_2x_up = np.array(dataset_B_images_2x_up).reshape(len(dataset_B_images_2x_up), -1)\n",
    "\n",
    "\n",
    "\n",
    "def knn_predict(X_train, y_train, X_test):\n",
    "    predictions = []\n",
    "    for i in range(len(X_test)):\n",
    "        # 一次计算所有距离\n",
    "        distances = np.linalg.norm(X_train - X_test[i], axis=1)\n",
    "        distances[i] = np.inf  # 排除自身\n",
    "        nearest_idx = np.argmin(distances)\n",
    "        predictions.append(y_train[nearest_idx])\n",
    "    return np.array(predictions)\n",
    "    \n",
    "start_time_2x_down = time.time()\n",
    "B_2x_down_predictions = knn_predict(dataset_A_images_2x_down,dataset_A_labels,dataset_B_images_2x_down)\n",
    "end_time_2x_down = time.time()\n",
    "\n",
    "start_time_4x_down = time.time()\n",
    "B_4x_down_predictions = knn_predict(dataset_A_images_4x_down,dataset_A_labels,dataset_B_images_4x_down)\n",
    "end_time_4x_down = time.time()\n",
    "\n",
    "start_time_2x_up = time.time()\n",
    "B_2x_up_predictions = knn_predict(dataset_A_images_2x_up,dataset_A_labels,dataset_B_images_2x_up)\n",
    "end_time_2x_up = time.time()\n",
    "\n",
    "accuracy_2x_down = np.mean(B_2x_down_predictions == dataset_B_labels)\n",
    "accuracy_4x_down = np.mean(B_4x_down_predictions == dataset_B_labels)\n",
    "accuracy_2x_up = np.mean(B_2x_up_predictions == dataset_B_labels)\n",
    "\n",
    "time_2x_down = end_time_2x_down - start_time_2x_down\n",
    "time_4x_down = end_time_4x_down - start_time_4x_down\n",
    "time_2x_up = end_time_2x_up - start_time_2x_up\n",
    "\n",
    "print('2倍降采样后准确率为',accuracy_2x_down,'用时为',time_2x_down)\n",
    "print('4倍降采样后准确率为',accuracy_4x_down,'用时为',time_4x_down)\n",
    "print('2倍分辨率插值后准确率为',accuracy_2x_up,'用时为',time_2x_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7403ba",
   "metadata": {},
   "source": [
    "## Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb857f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: (optional) rotation-invariant classifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
